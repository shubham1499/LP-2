{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\Stuff\\SEM7\\DMW\\Assign4\\SpamMessages.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Category'] = data['Category'].map({'ham':1, 'spam':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['Message']\n",
    "y=data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Based on English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing Dataset for Training and Testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6906)\t0.19953692618558513\n",
      "  (0, 881)\t0.34628724486515433\n",
      "  (0, 2987)\t0.1683291399808259\n",
      "  (0, 1688)\t0.29075681875837484\n",
      "  (0, 1440)\t0.3300456364043877\n",
      "  (0, 3726)\t0.302280423350998\n",
      "  (0, 7087)\t0.24057522428435282\n",
      "  (0, 3016)\t0.19953692618558513\n",
      "  (0, 1442)\t0.2961056503911323\n",
      "  (0, 1072)\t0.2629916057049851\n",
      "  (0, 1919)\t0.27800060198344656\n",
      "  (0, 4928)\t0.2745152102976083\n",
      "  (0, 3615)\t0.34628724486515433\n",
      "  (1, 4605)\t0.5330201590515121\n",
      "  (1, 6999)\t0.42857520326482806\n",
      "  (1, 3586)\t0.5523039540149847\n",
      "  (1, 3756)\t0.3979579482287257\n",
      "  (1, 4582)\t0.2623025333697874\n",
      "  (2, 65)\t0.23456789210887619\n",
      "  (2, 950)\t0.1730898313232928\n",
      "  (2, 5206)\t0.17201540710441182\n",
      "  (2, 6622)\t0.127052810957222\n",
      "  (2, 6046)\t0.20029215554321114\n",
      "  (2, 5160)\t0.18201930532845031\n",
      "  (2, 5251)\t0.17098006163262383\n",
      "  :\t:\n",
      "  (4174, 4108)\t0.34517439688938334\n",
      "  (4174, 5324)\t0.3320155782627741\n",
      "  (4174, 5500)\t0.23480481629465047\n",
      "  (4174, 4408)\t0.20891586855656302\n",
      "  (4174, 6780)\t0.23025943622198503\n",
      "  (4174, 4582)\t0.17898922221747168\n",
      "  (4174, 2987)\t0.19221525736823186\n",
      "  (4175, 4896)\t0.7328695265112698\n",
      "  (4175, 6911)\t0.35246545199843116\n",
      "  (4175, 2292)\t0.32889008722627794\n",
      "  (4175, 4899)\t0.4801058974674027\n",
      "  (4176, 5451)\t0.5478584187933532\n",
      "  (4176, 6939)\t0.5221626934615082\n",
      "  (4176, 5158)\t0.48978990808916584\n",
      "  (4176, 2241)\t0.329220783635052\n",
      "  (4176, 2959)\t0.28092133431086813\n",
      "  (4177, 5805)\t0.49371487354244514\n",
      "  (4177, 5494)\t0.407641715126613\n",
      "  (4177, 3737)\t0.5115766677544145\n",
      "  (4177, 6531)\t0.407641715126613\n",
      "  (4177, 6360)\t0.329859341866664\n",
      "  (4177, 3617)\t0.2310502443470128\n",
      "  (4178, 6482)\t0.6533441431994012\n",
      "  (4178, 3930)\t0.6969087412071227\n",
      "  (4178, 4582)\t0.29573575532245694\n"
     ]
    }
   ],
   "source": [
    "print(x_train_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6869)\t0.5758169262775346\n",
      "  (0, 4887)\t0.817578661299506\n",
      "  (1, 5615)\t0.33968833157370687\n",
      "  (1, 5342)\t0.6467685592484075\n",
      "  (1, 1996)\t0.37637293965859986\n",
      "  (1, 1869)\t0.5697768672499388\n",
      "  (2, 6721)\t0.23087536192367228\n",
      "  (2, 6527)\t0.4018539207814174\n",
      "  (2, 4582)\t0.23216802134258055\n",
      "  (2, 4209)\t0.30821904595371763\n",
      "  (2, 3949)\t0.25917161068611655\n",
      "  (2, 3244)\t0.29115066135548817\n",
      "  (2, 2132)\t0.44772783383883635\n",
      "  (2, 1532)\t0.32312971202485985\n",
      "  (2, 368)\t0.42367129688687594\n",
      "  (3, 7005)\t0.5080322602706842\n",
      "  (3, 4879)\t0.6107997821804426\n",
      "  (3, 4844)\t0.3979190210341076\n",
      "  (3, 4582)\t0.2900836198672183\n",
      "  (3, 1996)\t0.35544168972782625\n",
      "  (4, 6725)\t0.21547234025826992\n",
      "  (4, 5939)\t0.34455382946123725\n",
      "  (4, 5495)\t0.2669972014707784\n",
      "  (4, 3223)\t0.23282247419249047\n",
      "  (4, 1946)\t0.22826250977231527\n",
      "  :\t:\n",
      "  (1388, 4981)\t0.31719296855520557\n",
      "  (1388, 4383)\t0.27214573481635734\n",
      "  (1388, 4201)\t0.28745044138850284\n",
      "  (1388, 2354)\t0.26805603252570753\n",
      "  (1388, 1843)\t0.23369513851933063\n",
      "  (1388, 1694)\t0.21108101511544344\n",
      "  (1388, 1430)\t0.2643224268550682\n",
      "  (1388, 585)\t0.2844899989138587\n",
      "  (1388, 388)\t0.26805603252570753\n",
      "  (1388, 259)\t0.2743466991203007\n",
      "  (1389, 3228)\t0.36526151504314514\n",
      "  (1389, 2959)\t0.3558074104290555\n",
      "  (1389, 2774)\t0.5500833803541804\n",
      "  (1389, 2475)\t0.6613572309805601\n",
      "  (1390, 4282)\t1.0\n",
      "  (1391, 6945)\t0.2883268256615709\n",
      "  (1391, 3845)\t0.24057053302556572\n",
      "  (1391, 3454)\t0.4473420881322465\n",
      "  (1391, 3058)\t0.3732001348990244\n",
      "  (1391, 2878)\t0.4278666804675761\n",
      "  (1391, 2784)\t0.24155437268025307\n",
      "  (1391, 2145)\t0.2794044035278195\n",
      "  (1391, 1473)\t0.4473420881322465\n",
      "  (1392, 6581)\t0.6099700907834937\n",
      "  (1392, 5430)\t0.7924244369967248\n"
     ]
    }
   ],
   "source": [
    "x_test_vec = vectorizer.transform(x_test)\n",
    "print(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = nb.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Precision and Recall Value for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.9688\n",
      "Recall :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Precision : ', precision_score(y_test, prediction, average = \"binary\"))\n",
    "print('Recall : ', recall_score(y_test, prediction, average = \"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
